{"cells":[{"source":"Pneumonia is one of the leading respiratory illnesses worldwide, and its timely and accurate diagnosis is essential for effective treatment. Manually reviewing chest X-rays is a critical step in this process, and AI can provide valuable support by helping to expedite the assessment. In your role as a consultant data scientist, you will test the ability of a deep learning model to distinguish pneumonia cases from normal images of lungs in chest X-rays.\n\nBy fine-tuning a pre-trained convolutional neural network, specifically the ResNet-18 model, your task is to classify X-ray images into two categories: normal lungs and those affected by pneumonia. You can leverage its already trained weights and get an accurate classifier trained faster and with fewer resources.\n\n## The Data\n\n<img src=\"x-rays_sample.png\" align=\"center\"/>\n&nbsp\n\nYou have a dataset of chest X-rays that have been preprocessed for use with a ResNet-18 model. You can see a sample of 5 images from each category above. Upon unzipping the `chestxrays.zip` file (code provided below), you will find your dataset inside the `data/chestxrays` folder divided into `test` and `train` folders. \n\nThere are 150 training images and 50 testing images for each category, NORMAL and PNEUMONIA (300 and 100 in total). For your convenience, this data has already been loaded into a `train_loader` and a `test_loader` using the `DataLoader` class from the PyTorch library. ","metadata":{},"id":"85dc467a-5830-44c0-ab74-435be0e5593c","cell_type":"markdown"},{"source":"# # Make sure to run this cell to use torchmetrics.\n!pip install torch torchvision torchmetrics","metadata":{"executionCancelledAt":null,"executionTime":3148,"lastExecutedAt":1733777736521,"lastExecutedByKernel":"5ce40832-0a8a-4851-9b0e-8d5f292fdb0d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# # Make sure to run this cell to use torchmetrics.\n!pip install torch torchvision torchmetrics","outputsMetadata":{"0":{"height":0,"type":"stream"}}},"id":"0f522b79-2a5a-4472-adb9-0d924870bfa1","cell_type":"code","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0)\nRequirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.5.2)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.9.0)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.2)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.11.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"\n# Import required libraries\n# --------------------------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n# --------------------------------------------\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)\n\nimport os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')\n        \n# Define the transformations to apply to the images for use with ResNet-18.\n# The images need to be normalized to the same domain as the original training data of ResNet-18 network.\n# We normalize the X-rays using transforms.Normalize function that takes as input the means and\n# standard deviations of the three color channels, (R,G,B), from the original ResNet-18 training dataset.\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))\n\n#--------------------------\n# Q1: Instantiate the model\n#--------------------------\n\n# Load the pre-trained ResNet-18 model\nresnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n\n#--------------------------\n# Q2: Modify the model\n#--------------------------\n\n# Freeze the parameters of the model\nfor param in resnet18.parameters():\n    param.requires_grad = False\n\n# Modify the final layer for binary classification\nresnet18.fc = nn.Linear(resnet18.fc.in_features, 1)\n\n#------------------------------\n# Q3a: Define the training loop\n#------------------------------\n\n# Model training/fine-tuning loop\ndef train(model, train_loader, criterion, optimizer, num_epochs):\n    \n    # Train the model for the specified number of epochs\n    for epoch in range(num_epochs):\n        # Set the model to train mode\n        model.train()\n\n        # Initialize the running loss and accuracy\n        running_loss = 0.0\n        running_accuracy = 0\n\n        # Iterate over the batches of the train loader\n        for inputs, labels in train_loader:\n\n            # Zero the optimizer gradients\n            optimizer.zero_grad()\n            \n            # Ensure labels have the same dimensions as outputs\n            labels = labels.float().unsqueeze(1)\n\n            # Forward pass\n            outputs = model(inputs)\n            preds = torch.sigmoid(outputs) > 0.5 # Binary classification\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimizer step\n            loss.backward()\n            optimizer.step()\n\n            # Update the running loss and accuracy\n            running_loss += loss.item() * inputs.size(0)\n            running_accuracy += torch.sum(preds == labels.data)\n\n        # Calculate the train loss and accuracy for the current epoch\n        train_loss = running_loss / len(train_dataset)\n        train_acc = running_accuracy.double() / len(train_dataset)\n\n        # Print the epoch results\n        print('Epoch [{}/{}], train loss: {:.4f}, train acc: {:.4f}'\n              .format(epoch+1, num_epochs, train_loss, train_acc))\n\n#-------------------------\n# Q3b: Fine-tune the model\n#-------------------------        \n        \n# Set the model to ResNet-18\nmodel = resnet18\n\n# Fine-tune the ResNet-18 model for 3 epochs using the train_loader\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=0.01)\ncriterion = torch.nn.BCEWithLogitsLoss()\ntrain(model, train_loader, criterion, optimizer, num_epochs=100)\n\n#-----------------------\n# Evaluation code\n#----------------------- \n\n# Set model to evaluation mode\nmodel = resnet18\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists store all predictions and labels\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():  # Disable gradient calculation for evaluation\n  for inputs, labels in test_loader:\n    # Forward pass\n    outputs = model(inputs)\n    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n    # Extend the lists with predictions and labels\n    all_preds.extend(preds.tolist())\n    all_labels.extend(labels.unsqueeze(1).tolist())\n\n    # Convert lists back to tensors\n    all_preds = torch.tensor(all_preds)\n    all_labels = torch.tensor(all_labels)\n\n    # Calculate accuracy and F1 score\n    test_accuracy = accuracy_metric(all_preds, all_labels).item()\n    test_f1_score = f1_metric(all_preds, all_labels).item()\n \nprint(f\"\\nTest accuracy: {test_accuracy:.3f}\\nTest F1-score: {test_f1_score:.3f}\")\n\n\n#-----------------------------------------------------------------------------------\n# Below is a sample code for the bonus task.\n# This code divides the training set into training and validation subsets.\n# You will have 150 examples per class for training and 50 for validation.\n# Don't forget to create new `val_dataset` and `val_loader` after running this code.\n#-----------------------------------------------------------------------------------\n'''\nimport os, random, shutil\n\n# Function to move 50 random files from class folder in training to validation folder\ndef move_files(src_class_dir, dest_class_dir, n=50):\n    if not os.path.exists(dest_class_dir):\n        os.makedirs(dest_class_dir)\n    files = os.listdir(src_class_dir)\n    random_files = random.sample(files, n)\n    for f in random_files:\n        shutil.move(os.path.join(src_class_dir, f), os.path.join(dest_class_dir, f))\n\n# Move 50 images from each class to validation folder\nmove_files('data/chestxrays/train/NORMAL', 'data/chestxrays/val/NORMAL')\nmove_files('data/chestxrays/train/PNEUMONIA', 'data/chestxrays/val/PNEUMONIA')\n'''\n","metadata":{"executionCancelledAt":null,"executionTime":2313485,"lastExecutedAt":1733780050007,"lastExecutedByKernel":"5ce40832-0a8a-4851-9b0e-8d5f292fdb0d","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"\n# Import required libraries\n# --------------------------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n# --------------------------------------------\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)\n\nimport os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')\n        \n# Define the transformations to apply to the images for use with ResNet-18.\n# The images need to be normalized to the same domain as the original training data of ResNet-18 network.\n# We normalize the X-rays using transforms.Normalize function that takes as input the means and\n# standard deviations of the three color channels, (R,G,B), from the original ResNet-18 training dataset.\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))\n\n#--------------------------\n# Q1: Instantiate the model\n#--------------------------\n\n# Load the pre-trained ResNet-18 model\nresnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n\n#--------------------------\n# Q2: Modify the model\n#--------------------------\n\n# Freeze the parameters of the model\nfor param in resnet18.parameters():\n    param.requires_grad = False\n\n# Modify the final layer for binary classification\nresnet18.fc = nn.Linear(resnet18.fc.in_features, 1)\n\n#------------------------------\n# Q3a: Define the training loop\n#------------------------------\n\n# Model training/fine-tuning loop\ndef train(model, train_loader, criterion, optimizer, num_epochs):\n    \n    # Train the model for the specified number of epochs\n    for epoch in range(num_epochs):\n        # Set the model to train mode\n        model.train()\n\n        # Initialize the running loss and accuracy\n        running_loss = 0.0\n        running_accuracy = 0\n\n        # Iterate over the batches of the train loader\n        for inputs, labels in train_loader:\n\n            # Zero the optimizer gradients\n            optimizer.zero_grad()\n            \n            # Ensure labels have the same dimensions as outputs\n            labels = labels.float().unsqueeze(1)\n\n            # Forward pass\n            outputs = model(inputs)\n            preds = torch.sigmoid(outputs) > 0.5 # Binary classification\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimizer step\n            loss.backward()\n            optimizer.step()\n\n            # Update the running loss and accuracy\n            running_loss += loss.item() * inputs.size(0)\n            running_accuracy += torch.sum(preds == labels.data)\n\n        # Calculate the train loss and accuracy for the current epoch\n        train_loss = running_loss / len(train_dataset)\n        train_acc = running_accuracy.double() / len(train_dataset)\n\n        # Print the epoch results\n        print('Epoch [{}/{}], train loss: {:.4f}, train acc: {:.4f}'\n              .format(epoch+1, num_epochs, train_loss, train_acc))\n\n#-------------------------\n# Q3b: Fine-tune the model\n#-------------------------        \n        \n# Set the model to ResNet-18\nmodel = resnet18\n\n# Fine-tune the ResNet-18 model for 3 epochs using the train_loader\noptimizer = torch.optim.Adam(model.fc.parameters(), lr=0.01)\ncriterion = torch.nn.BCEWithLogitsLoss()\ntrain(model, train_loader, criterion, optimizer, num_epochs=100)\n\n#-----------------------\n# Evaluation code\n#----------------------- \n\n# Set model to evaluation mode\nmodel = resnet18\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists store all predictions and labels\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():  # Disable gradient calculation for evaluation\n  for inputs, labels in test_loader:\n    # Forward pass\n    outputs = model(inputs)\n    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n    # Extend the lists with predictions and labels\n    all_preds.extend(preds.tolist())\n    all_labels.extend(labels.unsqueeze(1).tolist())\n\n    # Convert lists back to tensors\n    all_preds = torch.tensor(all_preds)\n    all_labels = torch.tensor(all_labels)\n\n    # Calculate accuracy and F1 score\n    test_accuracy = accuracy_metric(all_preds, all_labels).item()\n    test_f1_score = f1_metric(all_preds, all_labels).item()\n \nprint(f\"\\nTest accuracy: {test_accuracy:.3f}\\nTest F1-score: {test_f1_score:.3f}\")\n\n\n#-----------------------------------------------------------------------------------\n# Below is a sample code for the bonus task.\n# This code divides the training set into training and validation subsets.\n# You will have 150 examples per class for training and 50 for validation.\n# Don't forget to create new `val_dataset` and `val_loader` after running this code.\n#-----------------------------------------------------------------------------------\n'''\nimport os, random, shutil\n\n# Function to move 50 random files from class folder in training to validation folder\ndef move_files(src_class_dir, dest_class_dir, n=50):\n    if not os.path.exists(dest_class_dir):\n        os.makedirs(dest_class_dir)\n    files = os.listdir(src_class_dir)\n    random_files = random.sample(files, n)\n    for f in random_files:\n        shutil.move(os.path.join(src_class_dir, f), os.path.join(dest_class_dir, f))\n\n# Move 50 images from each class to validation folder\nmove_files('data/chestxrays/train/NORMAL', 'data/chestxrays/val/NORMAL')\nmove_files('data/chestxrays/train/PNEUMONIA', 'data/chestxrays/val/PNEUMONIA')\n'''\n","outputsMetadata":{"0":{"height":0,"type":"stream"},"2":{"height":338,"type":"stream"}}},"cell_type":"code","id":"216636a6-25b1-4be0-a146-b5fe7135f941","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch [1/100], train loss: 1.3915, train acc: 0.4567\nEpoch [2/100], train loss: 0.8973, train acc: 0.4633\nEpoch [3/100], train loss: 0.9199, train acc: 0.5033\nEpoch [4/100], train loss: 0.4400, train acc: 0.8400\nEpoch [5/100], train loss: 0.5814, train acc: 0.6667\nEpoch [6/100], train loss: 0.3991, train acc: 0.8367\nEpoch [7/100], train loss: 0.3462, train acc: 0.8500\nEpoch [8/100], train loss: 0.3738, train acc: 0.8033\nEpoch [9/100], train loss: 0.2711, train acc: 0.9067\nEpoch [10/100], train loss: 0.2851, train acc: 0.8933\nEpoch [11/100], train loss: 0.2878, train acc: 0.8900\nEpoch [12/100], train loss: 0.2463, train acc: 0.9100\nEpoch [13/100], train loss: 0.2285, train acc: 0.9100\nEpoch [14/100], train loss: 0.2535, train acc: 0.8933\nEpoch [15/100], train loss: 0.2298, train acc: 0.9033\nEpoch [16/100], train loss: 0.2051, train acc: 0.9133\nEpoch [17/100], train loss: 0.2052, train acc: 0.9200\nEpoch [18/100], train loss: 0.2138, train acc: 0.9100\nEpoch [19/100], train loss: 0.1948, train acc: 0.9200\nEpoch [20/100], train loss: 0.1877, train acc: 0.9167\nEpoch [21/100], train loss: 0.1871, train acc: 0.9200\nEpoch [22/100], train loss: 0.1788, train acc: 0.9233\nEpoch [23/100], train loss: 0.1733, train acc: 0.9267\nEpoch [24/100], train loss: 0.1845, train acc: 0.9267\nEpoch [25/100], train loss: 0.1699, train acc: 0.9400\nEpoch [26/100], train loss: 0.1656, train acc: 0.9433\nEpoch [27/100], train loss: 0.1630, train acc: 0.9300\nEpoch [28/100], train loss: 0.1626, train acc: 0.9333\nEpoch [29/100], train loss: 0.1511, train acc: 0.9333\nEpoch [30/100], train loss: 0.1689, train acc: 0.9433\nEpoch [31/100], train loss: 0.1449, train acc: 0.9567\nEpoch [32/100], train loss: 0.1476, train acc: 0.9500\nEpoch [33/100], train loss: 0.1453, train acc: 0.9533\nEpoch [34/100], train loss: 0.1337, train acc: 0.9633\nEpoch [35/100], train loss: 0.1360, train acc: 0.9600\nEpoch [36/100], train loss: 0.1314, train acc: 0.9633\nEpoch [37/100], train loss: 0.1282, train acc: 0.9600\nEpoch [38/100], train loss: 0.1273, train acc: 0.9533\nEpoch [39/100], train loss: 0.1238, train acc: 0.9600\nEpoch [40/100], train loss: 0.1234, train acc: 0.9667\nEpoch [41/100], train loss: 0.1266, train acc: 0.9667\nEpoch [42/100], train loss: 0.1168, train acc: 0.9667\nEpoch [43/100], train loss: 0.1263, train acc: 0.9567\nEpoch [44/100], train loss: 0.1146, train acc: 0.9700\nEpoch [45/100], train loss: 0.1147, train acc: 0.9633\nEpoch [46/100], train loss: 0.1106, train acc: 0.9667\nEpoch [47/100], train loss: 0.1082, train acc: 0.9700\nEpoch [48/100], train loss: 0.1120, train acc: 0.9700\nEpoch [49/100], train loss: 0.1055, train acc: 0.9700\nEpoch [50/100], train loss: 0.1050, train acc: 0.9767\nEpoch [51/100], train loss: 0.1023, train acc: 0.9733\nEpoch [52/100], train loss: 0.1031, train acc: 0.9700\nEpoch [53/100], train loss: 0.1012, train acc: 0.9667\nEpoch [54/100], train loss: 0.0975, train acc: 0.9767\nEpoch [55/100], train loss: 0.1019, train acc: 0.9667\nEpoch [56/100], train loss: 0.0946, train acc: 0.9733\nEpoch [57/100], train loss: 0.0923, train acc: 0.9833\nEpoch [58/100], train loss: 0.0910, train acc: 0.9833\nEpoch [59/100], train loss: 0.0939, train acc: 0.9833\nEpoch [60/100], train loss: 0.0988, train acc: 0.9767\nEpoch [61/100], train loss: 0.0853, train acc: 0.9800\nEpoch [62/100], train loss: 0.0905, train acc: 0.9867\nEpoch [63/100], train loss: 0.0843, train acc: 0.9867\nEpoch [64/100], train loss: 0.0877, train acc: 0.9833\nEpoch [65/100], train loss: 0.0840, train acc: 0.9867\nEpoch [66/100], train loss: 0.0887, train acc: 0.9733\nEpoch [67/100], train loss: 0.0793, train acc: 0.9867\nEpoch [68/100], train loss: 0.0777, train acc: 0.9867\nEpoch [69/100], train loss: 0.0763, train acc: 0.9900\nEpoch [70/100], train loss: 0.0769, train acc: 0.9900\nEpoch [71/100], train loss: 0.0750, train acc: 0.9900\nEpoch [72/100], train loss: 0.0751, train acc: 0.9867\nEpoch [73/100], train loss: 0.0735, train acc: 0.9867\nEpoch [74/100], train loss: 0.0715, train acc: 0.9933\nEpoch [75/100], train loss: 0.0745, train acc: 0.9900\nEpoch [76/100], train loss: 0.0717, train acc: 0.9900\nEpoch [77/100], train loss: 0.0717, train acc: 0.9867\nEpoch [78/100], train loss: 0.0700, train acc: 0.9867\nEpoch [79/100], train loss: 0.0792, train acc: 0.9833\nEpoch [80/100], train loss: 0.0723, train acc: 0.9933\nEpoch [81/100], train loss: 0.0806, train acc: 0.9833\nEpoch [82/100], train loss: 0.0672, train acc: 0.9867\nEpoch [83/100], train loss: 0.0647, train acc: 0.9933\nEpoch [84/100], train loss: 0.0688, train acc: 0.9933\nEpoch [85/100], train loss: 0.0739, train acc: 0.9867\nEpoch [86/100], train loss: 0.0602, train acc: 0.9967\nEpoch [87/100], train loss: 0.0643, train acc: 0.9933\nEpoch [88/100], train loss: 0.0623, train acc: 0.9967\nEpoch [89/100], train loss: 0.0701, train acc: 0.9833\nEpoch [90/100], train loss: 0.0585, train acc: 0.9933\nEpoch [91/100], train loss: 0.0615, train acc: 0.9967\nEpoch [92/100], train loss: 0.0586, train acc: 0.9967\nEpoch [93/100], train loss: 0.0567, train acc: 0.9967\nEpoch [94/100], train loss: 0.0596, train acc: 0.9900\nEpoch [95/100], train loss: 0.0558, train acc: 0.9933\nEpoch [96/100], train loss: 0.0859, train acc: 0.9767\nEpoch [97/100], train loss: 0.0541, train acc: 0.9933\nEpoch [98/100], train loss: 0.0605, train acc: 0.9933\nEpoch [99/100], train loss: 0.0593, train acc: 0.9933\nEpoch [100/100], train loss: 0.0550, train acc: 0.9967\n\nTest accuracy: 0.780\nTest F1-score: 0.820\n"},{"output_type":"execute_result","data":{"text/plain":"\"\\nimport os, random, shutil\\n\\n# Function to move 50 random files from class folder in training to validation folder\\ndef move_files(src_class_dir, dest_class_dir, n=50):\\n    if not os.path.exists(dest_class_dir):\\n        os.makedirs(dest_class_dir)\\n    files = os.listdir(src_class_dir)\\n    random_files = random.sample(files, n)\\n    for f in random_files:\\n        shutil.move(os.path.join(src_class_dir, f), os.path.join(dest_class_dir, f))\\n\\n# Move 50 images from each class to validation folder\\nmove_files('data/chestxrays/train/NORMAL', 'data/chestxrays/val/NORMAL')\\nmove_files('data/chestxrays/train/PNEUMONIA', 'data/chestxrays/val/PNEUMONIA')\\n\""},"metadata":{},"execution_count":4}],"execution_count":4},{"source":"### Below is the provided model evaluation code. Run the below cell to help you evaluate the accuracy and F1-score of your fine-tuned model.","metadata":{},"id":"70761893-e66f-40fe-8862-dac9b18a13ab","cell_type":"markdown"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}